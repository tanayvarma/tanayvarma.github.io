<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Paraβurst  by tanayvarma</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Paraβurst </h1>
      <h2 class="project-tagline">Android Application to Detect Best Images in a Burst</h2>
    </section>

    <section class="main-content">
      <h1>
<a id="summary" class="anchor" href="#summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Summary</h1>

<p>We are going to create an Android application that efficiently uses the parallel processing capabilities of an Android-based machine’s GPU to rapidly perform parallel image analysis on a burst - several photographs captured in quick succession. </p>

<h1>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background</h1>

<p>We are interested in creating an application that can simplify and accelerate the process of selecting the best image from a burst. Specifically, a burst contains a large number of images and it is often cumbersome to sift through all the images to find the best one. Our application aims to detect the images with the highest rate of people with eyes open and smiling. If none of the images completely match all the parameters, then our application will create a composite image i.e. stitching together an image - from the entire library of burst - where everyone is smiling with their eyes open.</p>

<p>A sequential version of the application has several bottlenecks: </p>

<ol>
<li><p>Serial analysis and execution of each image in the burst will be extremely slow as there is a large number of photographs in burst.  We aim to provide a near real-time solution to the problem. </p></li>
<li><p>Sequentially analyzing each image for face and eye detection will be extremely slow, and applying a serial vision algorithm to all the images in the burst would take a long time and a lot of processing power. </p></li>
<li><p>Creating the composite image sequentially will be a bottleneck in the runtime of this application. </p></li>
<li><p>Most importantly, a sequential version of the whole application will not be able to benefit from the machine’s GPU power and will also slow down the CPU as it will perform a lot of tasks on the latter. </p></li>
</ol>

<p>Therefore, all the aforementioned aspects of the application can be significantly improved from parallelism. We plan to use OpenCL (Android’s version of CUDA) to exploit parallelism in the multi-core chip. The benefits of a parallel application be better understood using the following illustrations highlighting the difference between the sequential and parallel versions.     </p>

<p><img src="https://41.media.tumblr.com/1270c91a9a7156bc1350a5a6cd1d461b/tumblr_o4z04zwsvR1vqq9vno1_1280.png" alt="Photo Burst"></p>

<h3>
<a id="applying-to-the-sequential-version" class="anchor" href="#applying-to-the-sequential-version" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Applying to the Sequential Version</h3>

<p><img src="https://40.media.tumblr.com/868c2a42d8a9d40622f54073bf5ce8d8/tumblr_o4yz7zJJhj1vqq9vno1_1280.png" alt="s1">
<img src="https://40.media.tumblr.com/da4449b2dd52023d428dc9fa3b9abbae/tumblr_o4yz7zJJhj1vqq9vno2_1280.png" alt="s2">
<img src="https://41.media.tumblr.com/ee75219ce559843a0d2741cb5a2be96e/tumblr_o4yz7zJJhj1vqq9vno3_1280.png" alt="s3"></p>

<h3>
<a id="now-applying-to-the-parallel-version-for-illustration-assuming-a-4-core-machine" class="anchor" href="#now-applying-to-the-parallel-version-for-illustration-assuming-a-4-core-machine" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Now Applying to the parallel version (For illustration, assuming a 4 core machine)</h3>

<p><img src="https://36.media.tumblr.com/336163365d27f70217b9fc132706cfa0/tumblr_o4yz7zJJhj1vqq9vno4_1280.png" alt="p1"></p>

<h3>
<a id="sequential-algorithm-for-vision-analysis-image-taken-from-here" class="anchor" href="#sequential-algorithm-for-vision-analysis-image-taken-from-here" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sequential algorithm for Vision Analysis (Image taken from <a href="http://www.engineersgarage.com/sites/default/files/imagecache/Original/wysiwyg_imageupload/28714/Face-Recognition.jpg">here</a>)</h3>

<p><img src="https://41.media.tumblr.com/c91edb3ddcd24df5ba573a6a7dcfb80c/tumblr_o4yz7zJJhj1vqq9vno5_1280.png" alt="p2"></p>

<h3>
<a id="parallel-algorithm-for-vision-analysis-for-illustration-assuming-a-4-core-machine" class="anchor" href="#parallel-algorithm-for-vision-analysis-for-illustration-assuming-a-4-core-machine" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Parallel algorithm for Vision Analysis (For illustration, assuming a 4 core machine)</h3>

<p><img src="https://41.media.tumblr.com/53bf572785aa18dd9cc3ed5e806dde4e/tumblr_o4yz7zJJhj1vqq9vno6_1280.png" alt="p3"></p>

<h1>
<a id="the-challenge" class="anchor" href="#the-challenge" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Challenge</h1>

<p>The application is challenging in a number of ways: </p>

<ol>
<li><p>OpenCL is written in C/C++ whereas Android applications are written in Java. As we plan to make our code highly parallelizable to specific machines (fully exploiting our knowledge of the chips), we will have to compile C++ OpenCL code in our Java code.</p></li>
<li><p>As a burst contains a large number of images, there will be a high amount of memory accesses. This implies that a lot will depend on making sure that the computation-to-communication ratio is high. To ensure that the computation-to-communication ratio is high, we will need to handle cache optimizations of image data well in order to achieve maximum cache hits. </p></li>
<li><p>Efficiently detecting facial features is a lot more than simply sending different parts of the image to different cores; we will have to make sure that distribution of work is even and handle cases that require high computation with more processing power. </p></li>
<li><p>Stitching together an image will require a lot of inter-communication between processes and more processing power, which means that we will need to dynamically handle parallel processing of the code based not only on the dataset (burst) but also on what the algorithm is working on – eye detection, smile detection, stitching, etc. </p></li>
<li><p>During the analysis of each image, our application will perform numerous checks to see if the input meets some requirements. A high number of ‘if’ statements might cause divergent control flow execution, which will need to be handled in way that it does not affect accuracy at the cost of speedup. </p></li>
</ol>

<h1>
<a id="stretch-goal" class="anchor" href="#stretch-goal" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Stretch Goal</h1>

<p>We will further try to perform a quick image classification by parallelizing the popular 'Bag of Visual Words' algorithm. This Image classification can then be used to modify heuristics for detecting relevant image features and stitching.</p>

<p><img src="http://cs.brown.edu/courses/cs143/proj3/header.png" alt="p6"></p>

<h3>
<a id="references" class="anchor" href="#references" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>References</h3>

<p><a href="http://www1.cs.columbia.edu/CAVE/publications/pdfs/Bitouk_SIGGRAPH08.pdf">http://www1.cs.columbia.edu/CAVE/publications/pdfs/Bitouk_SIGGRAPH08.pdf</a>
<a href="https://daim.idi.ntnu.no/masteroppgaver/004/4762/masteroppgave.pdf">https://daim.idi.ntnu.no/masteroppgaver/004/4762/masteroppgave.pdf</a></p>

<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors and Contributors</h3>

<p>Tanay Varma (<a href="https://github.com/tanayvarma" class="user-mention">@tanayvarma</a>) and Mohak Nahta (<a href="https://github.com/mnahta" class="user-mention">@mnahta</a>)</p>

      <footer class="site-footer">

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
